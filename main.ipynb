{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvS1fOJMsW4S",
        "outputId": "a20149a2-55a4-42a9-eb2b-932d0917cadd",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/data.zip'\n",
        "target_dir = '/content'\n",
        "\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(target_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWgHBr75unKI",
        "outputId": "1ab79be2-7245-4d43-a967-c05857f229c7",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Collecting timm==1.0.13\n",
            "  Downloading timm-1.0.13-py3-none-any.whl.metadata (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m106.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm==1.0.13) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm==1.0.13) (0.24.0+cu126)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm==1.0.13) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm==1.0.13) (0.36.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm==1.0.13) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm==1.0.13) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm==1.0.13) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm==1.0.13) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.13) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.13) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.13) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.13) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.13) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.13) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.13) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.13) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.13) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.13) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.13) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.13) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.13) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.13) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.13) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.13) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.13) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.13) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.13) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.13) (3.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm==1.0.13) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->timm==1.0.13) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->timm==1.0.13) (3.0.3)\n",
            "Downloading timm-1.0.13-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: yacs, timm\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.22\n",
            "    Uninstalling timm-1.0.22:\n",
            "      Successfully uninstalled timm-1.0.22\n",
            "Successfully installed timm-1.0.13 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers timm==1.0.13 yacs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/lucinnnal/Intelligence_Vision.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2I9pdnxIpLS",
        "outputId": "71a47970-4f24-49ad-b3b8-1dcf4ae11a79"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Intelligence_Vision'...\n",
            "remote: Enumerating objects: 90, done.\u001b[K\n",
            "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 90 (delta 34), reused 88 (delta 32), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (90/90), 1.40 MiB | 26.09 MiB/s, done.\n",
            "Resolving deltas: 100% (34/34), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "source_path = '/content/data'\n",
        "destination_path = '/content/Intelligence_Vision/data'\n",
        "\n",
        "if os.path.exists(source_path):\n",
        "    # If destination exists and is not empty, remove it first\n",
        "    if os.path.exists(destination_path):\n",
        "        if os.path.isdir(destination_path) and len(os.listdir(destination_path)) > 0:\n",
        "            print(f\"Destination directory '{destination_path}' exists and is not empty. Removing it.\")\n",
        "            shutil.rmtree(destination_path)\n",
        "        elif os.path.isdir(destination_path) and len(os.listdir(destination_path)) == 0:\n",
        "            print(f\"Destination directory '{destination_path}' exists but is empty. Removing it.\")\n",
        "            os.rmdir(destination_path)\n",
        "        elif os.path.isfile(destination_path):\n",
        "            print(f\"Destination path '{destination_path}' is a file. Removing it.\")\n",
        "            os.remove(destination_path)\n",
        "\n",
        "    # Now, move the source to the destination\n",
        "    shutil.move(source_path, destination_path)\n",
        "    print(f\"Moved '{source_path}' to '{destination_path}'\")\n",
        "else:\n",
        "    print(f\"Source directory '{source_path}' does not exist.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-m2wjE_2JJcm",
        "outputId": "7276887d-287d-4fe5-dd09-f7befc81b5fb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Destination directory '/content/Intelligence_Vision/data' exists and is not empty. Removing it.\n",
            "Moved '/content/data' to '/content/Intelligence_Vision/data'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Intelligence_Vision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_D0U0UsIylk",
        "outputId": "a99d43e7-2694-4065-a342-5f52fa752573"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Intelligence_Vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --config /content/Intelligence_Vision/configs/clip.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBydegWbJwb-",
        "outputId": "5a71d24f-0a6f-43ef-d588-c0f222adb124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-17 12:08:27.769572: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765973307.802472     901 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765973307.812687     901 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765973307.837144     901 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765973307.837170     901 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765973307.837177     901 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765973307.837184     901 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-17 12:08:27.844093: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.12/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "Configuration loaded from /content/Intelligence_Vision/configs/clip.json\n",
            "Using device: cuda\n",
            "Scanning train dataset in ./data/train...\n",
            "  [ADM] found 799 images\n",
            "  [DDPM] found 800 images\n",
            "  [Diff-ProjectedGAN] found 800 images\n",
            "  [Diff-StyleGAN2] found 800 images\n",
            "  [IDDPM] found 800 images\n",
            "  [LDM] found 800 images\n",
            "  [PNDM] found 800 images\n",
            "  [ProGAN] found 800 images\n",
            "  [ProjectedGAN] found 800 images\n",
            "  [StyleGAN] found 800 images\n",
            "Total train images: 7999\n",
            "\n",
            "Scanning val dataset in ./data/val...\n",
            "  [ADM] found 100 images\n",
            "  [DDPM] found 100 images\n",
            "  [Diff-ProjectedGAN] found 100 images\n",
            "  [Diff-StyleGAN2] found 100 images\n",
            "  [IDDPM] found 100 images\n",
            "  [LDM] found 100 images\n",
            "  [PNDM] found 100 images\n",
            "  [ProGAN] found 100 images\n",
            "  [ProjectedGAN] found 100 images\n",
            "  [StyleGAN] found 100 images\n",
            "Total val images: 1000\n",
            "\n",
            "Scanning test dataset in ./data/test...\n",
            "  [ADM] found 101 images\n",
            "  [DDPM] found 100 images\n",
            "  [Diff-ProjectedGAN] found 100 images\n",
            "  [Diff-StyleGAN2] found 100 images\n",
            "  [IDDPM] found 100 images\n",
            "  [LDM] found 100 images\n",
            "  [PNDM] found 100 images\n",
            "  [ProGAN] found 100 images\n",
            "  [ProjectedGAN] found 100 images\n",
            "  [StyleGAN] found 100 images\n",
            "Total test images: 1001\n",
            "\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Loading CLIP model: openai/clip-vit-base-patch32\n",
            "config.json: 4.19kB [00:00, 18.0MB/s]\n",
            "pytorch_model.bin: 100% 605M/605M [00:03<00:00, 161MB/s]\n",
            "model.safetensors:   0% 0.00/605M [00:00<?, ?B/s]Training parameters: Classifier\n",
            "Freezing parameters: CLIP Encoder\n",
            "\n",
            "Optimizer: AdamW, Scheduler: CosineAnnealingLR\n",
            "\n",
            "--- Starting Training ---\n",
            "\n",
            "Epoch 1/20\n",
            "\n",
            "model.safetensors: 100% 605M/605M [00:05<00:00, 112MB/s]\n",
            "\n",
            "Training:   0% 0/250 [00:05<?, ?it/s, loss=2.4386, acc=6.25%]\u001b[A\n",
            "Training:   0% 1/250 [00:05<21:06,  5.09s/it, loss=2.4386, acc=6.25%]\u001b[A\n",
            "Training:   0% 1/250 [00:05<21:06,  5.09s/it, loss=2.3525, acc=7.81%]\u001b[A\n",
            "Training:   1% 2/250 [00:05<08:59,  2.17s/it, loss=2.3525, acc=7.81%]\u001b[A\n",
            "Training:   1% 2/250 [00:05<08:59,  2.17s/it, loss=2.2367, acc=9.38%]\u001b[A\n",
            "Training:   1% 3/250 [00:05<05:05,  1.24s/it, loss=2.2367, acc=9.38%]\u001b[A\n",
            "Training:   1% 3/250 [00:05<05:05,  1.24s/it, loss=2.4239, acc=10.16%]\u001b[A\n",
            "Training:   2% 4/250 [00:05<03:13,  1.27it/s, loss=2.4239, acc=10.16%]\u001b[A\n",
            "Training:   2% 4/250 [00:05<03:13,  1.27it/s, loss=2.4259, acc=10.00%]\u001b[A\n",
            "Training:   2% 4/250 [00:05<03:13,  1.27it/s, loss=2.5273, acc=10.42%]\u001b[A\n",
            "Training:   2% 6/250 [00:05<01:44,  2.35it/s, loss=2.5273, acc=10.42%]\u001b[A\n",
            "Training:   2% 6/250 [00:05<01:44,  2.35it/s, loss=2.5274, acc=8.93%] \u001b[A\n",
            "Training:   2% 6/250 [00:05<01:44,  2.35it/s, loss=2.3592, acc=8.98%]\u001b[A\n",
            "Training:   3% 8/250 [00:05<01:08,  3.52it/s, loss=2.3592, acc=8.98%]\u001b[A\n",
            "Training:   3% 8/250 [00:05<01:08,  3.52it/s, loss=2.3431, acc=10.42%]\u001b[A\n",
            "Training:   4% 9/250 [00:05<00:58,  4.12it/s, loss=2.3431, acc=10.42%]\u001b[A\n",
            "Training:   4% 9/250 [00:06<00:58,  4.12it/s, loss=2.3923, acc=10.62%]\u001b[A\n",
            "Training:   4% 9/250 [00:06<00:58,  4.12it/s, loss=2.3231, acc=11.08%]\u001b[A\n",
            "Training:   4% 11/250 [00:06<00:44,  5.38it/s, loss=2.3231, acc=11.08%]\u001b[A\n",
            "Training:   4% 11/250 [00:06<00:44,  5.38it/s, loss=2.2851, acc=11.72%]\u001b[A\n",
            "Training:   5% 12/250 [00:06<00:39,  5.98it/s, loss=2.2851, acc=11.72%]\u001b[A\n",
            "Training:   5% 12/250 [00:06<00:39,  5.98it/s, loss=2.3819, acc=11.54%]\u001b[A\n",
            "Training:   5% 13/250 [00:06<00:37,  6.35it/s, loss=2.3819, acc=11.54%]\u001b[A\n",
            "Training:   5% 13/250 [00:06<00:37,  6.35it/s, loss=2.2472, acc=12.50%]\u001b[A\n",
            "Training:   5% 13/250 [00:06<00:37,  6.35it/s, loss=2.2459, acc=12.71%]\u001b[A\n",
            "Training:   6% 15/250 [00:06<00:31,  7.50it/s, loss=2.2459, acc=12.71%]\u001b[A\n",
            "Training:   6% 15/250 [00:06<00:31,  7.50it/s, loss=2.3708, acc=13.09%]\u001b[A\n",
            "Training:   6% 15/250 [00:06<00:31,  7.50it/s, loss=2.1538, acc=13.42%]\u001b[A\n",
            "Training:   7% 17/250 [00:06<00:27,  8.36it/s, loss=2.1538, acc=13.42%]\u001b[A\n",
            "Training:   7% 17/250 [00:06<00:27,  8.36it/s, loss=2.2845, acc=13.02%]\u001b[A\n",
            "Training:   7% 18/250 [00:06<00:27,  8.57it/s, loss=2.2845, acc=13.02%]\u001b[A\n",
            "Training:   7% 18/250 [00:07<00:27,  8.57it/s, loss=2.3858, acc=12.50%]\u001b[A\n",
            "Training:   8% 19/250 [00:07<00:27,  8.46it/s, loss=2.3858, acc=12.50%]\u001b[A\n",
            "Training:   8% 19/250 [00:07<00:27,  8.46it/s, loss=2.1812, acc=13.12%]\u001b[A\n",
            "Training:   8% 20/250 [00:07<00:27,  8.41it/s, loss=2.1812, acc=13.12%]\u001b[A\n",
            "Training:   8% 20/250 [00:07<00:27,  8.41it/s, loss=2.2455, acc=13.39%]\u001b[A\n",
            "Training:   8% 21/250 [00:07<00:31,  7.27it/s, loss=2.2455, acc=13.39%]\u001b[A\n",
            "Training:   8% 21/250 [00:07<00:31,  7.27it/s, loss=2.4090, acc=13.21%]\u001b[A\n",
            "Training:   9% 22/250 [00:07<00:29,  7.72it/s, loss=2.4090, acc=13.21%]\u001b[A\n",
            "Training:   9% 22/250 [00:07<00:29,  7.72it/s, loss=2.2511, acc=13.32%]\u001b[A\n",
            "Training:   9% 23/250 [00:07<00:27,  8.13it/s, loss=2.2511, acc=13.32%]\u001b[A\n",
            "Training:   9% 23/250 [00:07<00:27,  8.13it/s, loss=2.2949, acc=13.41%]\u001b[A\n",
            "Training:  10% 24/250 [00:07<00:27,  8.18it/s, loss=2.2949, acc=13.41%]\u001b[A\n",
            "Training:  10% 24/250 [00:07<00:27,  8.18it/s, loss=2.2626, acc=13.50%]\u001b[A\n",
            "Training:  10% 25/250 [00:07<00:26,  8.48it/s, loss=2.2626, acc=13.50%]\u001b[A\n",
            "Training:  10% 25/250 [00:07<00:26,  8.48it/s, loss=2.2063, acc=13.58%]\u001b[A\n",
            "Training:  10% 25/250 [00:07<00:26,  8.48it/s, loss=2.1738, acc=13.77%]\u001b[A\n",
            "Training:  11% 27/250 [00:07<00:26,  8.51it/s, loss=2.1738, acc=13.77%]\u001b[A\n",
            "Training:  11% 27/250 [00:08<00:26,  8.51it/s, loss=2.2413, acc=14.06%]\u001b[A\n",
            "Training:  11% 28/250 [00:08<00:31,  7.12it/s, loss=2.2413, acc=14.06%]\u001b[A\n",
            "Training:  11% 28/250 [00:08<00:31,  7.12it/s, loss=2.2056, acc=14.22%]\u001b[A\n",
            "Training:  12% 29/250 [00:08<00:29,  7.61it/s, loss=2.2056, acc=14.22%]\u001b[A\n",
            "Training:  12% 29/250 [00:08<00:29,  7.61it/s, loss=2.2032, acc=14.38%]\u001b[A\n",
            "Training:  12% 30/250 [00:08<00:27,  8.08it/s, loss=2.2032, acc=14.38%]\u001b[A\n",
            "Training:  12% 30/250 [00:08<00:27,  8.08it/s, loss=2.1507, acc=14.52%]\u001b[A\n",
            "Training:  12% 31/250 [00:08<00:25,  8.47it/s, loss=2.1507, acc=14.52%]\u001b[A\n",
            "Training:  12% 31/250 [00:08<00:25,  8.47it/s, loss=2.1154, acc=14.84%]\u001b[A\n",
            "Training:  13% 32/250 [00:08<00:37,  5.83it/s, loss=2.1154, acc=14.84%]\u001b[A\n",
            "Training:  13% 32/250 [00:08<00:37,  5.83it/s, loss=2.3486, acc=14.96%]\u001b[A\n",
            "Training:  13% 33/250 [00:08<00:32,  6.59it/s, loss=2.3486, acc=14.96%]\u001b[A\n",
            "Training:  13% 33/250 [00:09<00:32,  6.59it/s, loss=2.1295, acc=15.17%]\u001b[A\n",
            "Training:  14% 34/250 [00:09<00:29,  7.21it/s, loss=2.1295, acc=15.17%]\u001b[A\n",
            "Training:  14% 34/250 [00:09<00:29,  7.21it/s, loss=2.0761, acc=15.36%]\u001b[A\n",
            "Training:  14% 35/250 [00:09<00:28,  7.52it/s, loss=2.0761, acc=15.36%]\u001b[A\n",
            "Training:  14% 35/250 [00:09<00:28,  7.52it/s, loss=2.1519, acc=15.54%]\u001b[A\n",
            "Training:  14% 36/250 [00:09<00:37,  5.73it/s, loss=2.1519, acc=15.54%]\u001b[A\n",
            "Training:  14% 36/250 [00:09<00:37,  5.73it/s, loss=2.1227, acc=15.96%]\u001b[A\n",
            "Training:  14% 36/250 [00:09<00:37,  5.73it/s, loss=2.2235, acc=16.04%]\u001b[A\n",
            "Training:  15% 38/250 [00:09<00:29,  7.11it/s, loss=2.2235, acc=16.04%]\u001b[A\n",
            "Training:  15% 38/250 [00:09<00:29,  7.11it/s, loss=2.0414, acc=16.27%]\u001b[A\n",
            "Training:  15% 38/250 [00:09<00:29,  7.11it/s, loss=2.1856, acc=16.41%]\u001b[A\n",
            "Training:  16% 40/250 [00:09<00:29,  7.07it/s, loss=2.1856, acc=16.41%]\u001b[A\n",
            "Training:  16% 40/250 [00:10<00:29,  7.07it/s, loss=1.9217, acc=16.92%]\u001b[A\n",
            "Training:  16% 40/250 [00:10<00:29,  7.07it/s, loss=2.0763, acc=17.26%]\u001b[A\n",
            "Training:  17% 42/250 [00:10<00:26,  7.89it/s, loss=2.0763, acc=17.26%]\u001b[A\n",
            "Training:  17% 42/250 [00:10<00:26,  7.89it/s, loss=1.9414, acc=17.81%]\u001b[A\n",
            "Training:  17% 43/250 [00:10<00:25,  8.12it/s, loss=1.9414, acc=17.81%]\u001b[A\n",
            "Training:  17% 43/250 [00:10<00:25,  8.12it/s, loss=1.8414, acc=18.18%]\u001b[A\n",
            "Training:  18% 44/250 [00:10<00:33,  6.18it/s, loss=1.8414, acc=18.18%]\u001b[A\n",
            "Training:  18% 44/250 [00:10<00:33,  6.18it/s, loss=1.8028, acc=18.96%]\u001b[A\n",
            "Training:  18% 44/250 [00:10<00:33,  6.18it/s, loss=1.9860, acc=19.02%]\u001b[A\n",
            "Training:  18% 46/250 [00:10<00:27,  7.30it/s, loss=1.9860, acc=19.02%]\u001b[A\n",
            "Training:  18% 46/250 [00:10<00:27,  7.30it/s, loss=2.0792, acc=19.02%]\u001b[A\n",
            "Training:  18% 46/250 [00:11<00:27,  7.30it/s, loss=2.0361, acc=19.27%]\u001b[A\n",
            "Training:  19% 48/250 [00:11<00:29,  6.85it/s, loss=2.0361, acc=19.27%]\u001b[A\n",
            "Training:  19% 48/250 [00:11<00:29,  6.85it/s, loss=1.7853, acc=19.83%]\u001b[A\n",
            "Training:  20% 49/250 [00:11<00:27,  7.31it/s, loss=1.7853, acc=19.83%]\u001b[A\n",
            "Training:  20% 49/250 [00:11<00:27,  7.31it/s, loss=1.6784, acc=20.31%]\u001b[A\n",
            "Training:  20% 50/250 [00:11<00:26,  7.61it/s, loss=1.6784, acc=20.31%]\u001b[A\n",
            "Training:  20% 50/250 [00:11<00:26,  7.61it/s, loss=1.8068, acc=20.53%]\u001b[A\n",
            "Training:  20% 50/250 [00:11<00:26,  7.61it/s, loss=1.6766, acc=20.91%]\u001b[A\n",
            "Training:  21% 52/250 [00:11<00:40,  4.86it/s, loss=1.6766, acc=20.91%]\u001b[A\n",
            "Training:  21% 52/250 [00:12<00:40,  4.86it/s, loss=1.6236, acc=21.46%]\u001b[A\n",
            "Training:  21% 53/250 [00:12<00:37,  5.30it/s, loss=1.6236, acc=21.46%]\u001b[A\n",
            "Training:  21% 53/250 [00:12<00:37,  5.30it/s, loss=1.5417, acc=21.99%]\u001b[A\n",
            "Training:  22% 54/250 [00:12<00:33,  5.82it/s, loss=1.5417, acc=21.99%]\u001b[A\n",
            "Training:  22% 54/250 [00:12<00:33,  5.82it/s, loss=1.9802, acc=22.10%]\u001b[A\n",
            "Training:  22% 55/250 [00:12<00:31,  6.27it/s, loss=1.9802, acc=22.10%]\u001b[A\n",
            "Training:  22% 55/250 [00:12<00:31,  6.27it/s, loss=1.5984, acc=22.71%]\u001b[A\n",
            "Training:  22% 56/250 [00:12<00:45,  4.23it/s, loss=1.5984, acc=22.71%]\u001b[A\n",
            "Training:  22% 56/250 [00:12<00:45,  4.23it/s, loss=1.7248, acc=22.86%]\u001b[A\n",
            "Training:  23% 57/250 [00:12<00:38,  4.97it/s, loss=1.7248, acc=22.86%]\u001b[A\n",
            "Training:  23% 57/250 [00:12<00:38,  4.97it/s, loss=1.6411, acc=23.28%]\u001b[A\n",
            "Training:  23% 58/250 [00:12<00:33,  5.66it/s, loss=1.6411, acc=23.28%]\u001b[A\n",
            "Training:  23% 58/250 [00:13<00:33,  5.66it/s, loss=1.6626, acc=23.68%]\u001b[A\n",
            "Training:  24% 59/250 [00:13<00:30,  6.26it/s, loss=1.6626, acc=23.68%]\u001b[A\n",
            "Training:  24% 59/250 [00:13<00:30,  6.26it/s, loss=1.8311, acc=23.75%]\u001b[A\n",
            "Training:  24% 60/250 [00:13<00:49,  3.87it/s, loss=1.8311, acc=23.75%]\u001b[A\n",
            "Training:  24% 60/250 [00:13<00:49,  3.87it/s, loss=1.6484, acc=24.23%]\u001b[A\n",
            "Training:  24% 61/250 [00:13<00:42,  4.48it/s, loss=1.6484, acc=24.23%]\u001b[A\n",
            "Training:  24% 61/250 [00:13<00:42,  4.48it/s, loss=1.6397, acc=24.45%]\u001b[A\n",
            "Training:  25% 62/250 [00:13<00:36,  5.19it/s, loss=1.6397, acc=24.45%]\u001b[A\n",
            "Training:  25% 62/250 [00:13<00:36,  5.19it/s, loss=1.8441, acc=24.50%]\u001b[A\n",
            "Training:  25% 63/250 [00:13<00:32,  5.78it/s, loss=1.8441, acc=24.50%]\u001b[A\n",
            "Training:  25% 63/250 [00:14<00:32,  5.78it/s, loss=1.4514, acc=24.90%]\u001b[A\n",
            "Training:  26% 64/250 [00:14<00:46,  4.00it/s, loss=1.4514, acc=24.90%]\u001b[A\n",
            "Training:  26% 64/250 [00:14<00:46,  4.00it/s, loss=1.5700, acc=25.00%]\u001b[A\n",
            "Training:  26% 65/250 [00:14<00:38,  4.75it/s, loss=1.5700, acc=25.00%]\u001b[A\n",
            "Training:  26% 65/250 [00:14<00:38,  4.75it/s, loss=1.6660, acc=25.14%]\u001b[A\n",
            "Training:  26% 66/250 [00:14<00:32,  5.61it/s, loss=1.6660, acc=25.14%]\u001b[A\n",
            "Training:  26% 66/250 [00:14<00:32,  5.61it/s, loss=1.6798, acc=25.23%]\u001b[A\n",
            "Training:  27% 67/250 [00:14<00:29,  6.26it/s, loss=1.6798, acc=25.23%]\u001b[A\n",
            "Training:  27% 67/250 [00:15<00:29,  6.26it/s, loss=1.5087, acc=25.60%]\u001b[A\n",
            "Training:  27% 68/250 [00:15<00:47,  3.80it/s, loss=1.5087, acc=25.60%]\u001b[A\n",
            "Training:  27% 68/250 [00:15<00:47,  3.80it/s, loss=1.4960, acc=26.00%]\u001b[A\n",
            "Training:  28% 69/250 [00:15<00:40,  4.48it/s, loss=1.4960, acc=26.00%]\u001b[A\n",
            "Training:  28% 69/250 [00:15<00:40,  4.48it/s, loss=1.6795, acc=26.21%]\u001b[A\n",
            "Training:  28% 70/250 [00:15<00:34,  5.28it/s, loss=1.6795, acc=26.21%]\u001b[A\n",
            "Training:  28% 70/250 [00:15<00:34,  5.28it/s, loss=1.4630, acc=26.54%]\u001b[A\n",
            "Training:  28% 70/250 [00:15<00:34,  5.28it/s, loss=1.4217, acc=26.82%]\u001b[A\n",
            "Training:  29% 72/250 [00:15<00:30,  5.83it/s, loss=1.4217, acc=26.82%]\u001b[A\n",
            "Training:  29% 72/250 [00:15<00:30,  5.83it/s, loss=1.9523, acc=26.76%]\u001b[A\n",
            "Training:  29% 72/250 [00:15<00:30,  5.83it/s, loss=1.6730, acc=26.90%]\u001b[A\n",
            "Training:  30% 74/250 [00:15<00:26,  6.76it/s, loss=1.6730, acc=26.90%]\u001b[A\n",
            "Training:  30% 74/250 [00:16<00:26,  6.76it/s, loss=1.3846, acc=27.29%]\u001b[A\n",
            "Training:  30% 74/250 [00:16<00:26,  6.76it/s, loss=1.2164, acc=27.80%]\u001b[A\n",
            "Training:  30% 76/250 [00:16<00:23,  7.36it/s, loss=1.2164, acc=27.80%]\u001b[A\n",
            "Training:  30% 76/250 [00:16<00:23,  7.36it/s, loss=1.4549, acc=28.12%]\u001b[A\n",
            "Training:  30% 76/250 [00:16<00:23,  7.36it/s, loss=1.5395, acc=28.41%]\u001b[A\n",
            "Training:  31% 78/250 [00:16<00:24,  7.06it/s, loss=1.5395, acc=28.41%]\u001b[A\n",
            "Training:  31% 78/250 [00:16<00:24,  7.06it/s, loss=1.3542, acc=28.88%]\u001b[A\n",
            "Training:  32% 79/250 [00:16<00:22,  7.47it/s, loss=1.3542, acc=28.88%]\u001b[A\n",
            "Training:  32% 79/250 [00:16<00:22,  7.47it/s, loss=1.5263, acc=29.14%]\u001b[A\n",
            "Training:  32% 80/250 [00:16<00:22,  7.40it/s, loss=1.5263, acc=29.14%]\u001b[A\n",
            "Training:  32% 80/250 [00:16<00:22,  7.40it/s, loss=1.4099, acc=29.28%]\u001b[A\n",
            "Training:  32% 81/250 [00:16<00:21,  7.84it/s, loss=1.4099, acc=29.28%]\u001b[A\n",
            "Training:  32% 81/250 [00:17<00:21,  7.84it/s, loss=1.5012, acc=29.54%]\u001b[A\n",
            "Training:  33% 82/250 [00:17<00:24,  6.96it/s, loss=1.5012, acc=29.54%]\u001b[A\n",
            "Training:  33% 82/250 [00:17<00:24,  6.96it/s, loss=1.6382, acc=29.52%]\u001b[A\n",
            "Training:  33% 83/250 [00:17<00:22,  7.54it/s, loss=1.6382, acc=29.52%]\u001b[A\n",
            "Training:  33% 83/250 [00:17<00:22,  7.54it/s, loss=1.7676, acc=29.54%]\u001b[A\n",
            "Training:  34% 84/250 [00:17<00:20,  7.91it/s, loss=1.7676, acc=29.54%]\u001b[A\n",
            "Training:  34% 84/250 [00:17<00:20,  7.91it/s, loss=1.1854, acc=29.85%]\u001b[A\n",
            "Training:  34% 85/250 [00:17<00:20,  8.14it/s, loss=1.1854, acc=29.85%]\u001b[A\n",
            "Training:  34% 85/250 [00:17<00:20,  8.14it/s, loss=1.2027, acc=30.20%]\u001b[A\n",
            "Training:  34% 86/250 [00:17<00:28,  5.81it/s, loss=1.2027, acc=30.20%]\u001b[A\n",
            "Training:  34% 86/250 [00:17<00:28,  5.81it/s, loss=1.2834, acc=30.53%]\u001b[A\n",
            "Training:  35% 87/250 [00:17<00:25,  6.47it/s, loss=1.2834, acc=30.53%]\u001b[A\n",
            "Training:  35% 87/250 [00:17<00:25,  6.47it/s, loss=1.7068, acc=30.58%]\u001b[A\n",
            "Training:  35% 88/250 [00:17<00:26,  6.04it/s, loss=1.7068, acc=30.58%]\u001b[A\n",
            "Training:  35% 88/250 [00:18<00:26,  6.04it/s, loss=1.3464, acc=30.76%]\u001b[A\n",
            "Training:  36% 89/250 [00:18<00:23,  6.77it/s, loss=1.3464, acc=30.76%]\u001b[A\n",
            "Training:  36% 89/250 [00:18<00:23,  6.77it/s, loss=1.4392, acc=31.01%]\u001b[A\n",
            "Training:  36% 90/250 [00:18<00:24,  6.52it/s, loss=1.4392, acc=31.01%]\u001b[A\n",
            "Training:  36% 90/250 [00:18<00:24,  6.52it/s, loss=1.2252, acc=31.32%]\u001b[A\n",
            "Training:  36% 90/250 [00:18<00:24,  6.52it/s, loss=1.4800, acc=31.56%]\u001b[A\n",
            "Training:  37% 92/250 [00:18<00:22,  7.12it/s, loss=1.4800, acc=31.56%]\u001b[A\n",
            "Training:  37% 92/250 [00:18<00:22,  7.12it/s, loss=1.3625, acc=31.75%]\u001b[A\n",
            "Training:  37% 93/250 [00:18<00:20,  7.60it/s, loss=1.3625, acc=31.75%]\u001b[A\n",
            "Training:  37% 93/250 [00:18<00:20,  7.60it/s, loss=1.3679, acc=31.85%]\u001b[A\n",
            "Training:  38% 94/250 [00:18<00:24,  6.38it/s, loss=1.3679, acc=31.85%]\u001b[A\n",
            "Training:  38% 94/250 [00:18<00:24,  6.38it/s, loss=1.0590, acc=32.30%]\u001b[A\n",
            "Training:  38% 95/250 [00:18<00:22,  7.02it/s, loss=1.0590, acc=32.30%]\u001b[A\n",
            "Training:  38% 95/250 [00:19<00:22,  7.02it/s, loss=1.3635, acc=32.45%]\u001b[A\n",
            "Training:  38% 96/250 [00:19<00:20,  7.47it/s, loss=1.3635, acc=32.45%]\u001b[A\n",
            "Training:  38% 96/250 [00:19<00:20,  7.47it/s, loss=1.1451, acc=32.80%]\u001b[A\n",
            "Training:  38% 96/250 [00:19<00:20,  7.47it/s, loss=1.3233, acc=32.94%]\u001b[A\n",
            "Training:  39% 98/250 [00:19<00:23,  6.47it/s, loss=1.3233, acc=32.94%]\u001b[A\n",
            "Training:  39% 98/250 [00:19<00:23,  6.47it/s, loss=1.2749, acc=33.24%]\u001b[A\n",
            "Training:  39% 98/250 [00:19<00:23,  6.47it/s, loss=1.4622, acc=33.34%]\u001b[A\n",
            "Training:  40% 100/250 [00:19<00:19,  7.60it/s, loss=1.4622, acc=33.34%]\u001b[A\n",
            "Training:  40% 100/250 [00:19<00:19,  7.60it/s, loss=1.2519, acc=33.57%]\u001b[A\n",
            "Training:  40% 101/250 [00:19<00:18,  7.93it/s, loss=1.2519, acc=33.57%]\u001b[A\n",
            "Training:  40% 101/250 [00:19<00:18,  7.93it/s, loss=1.1966, acc=33.79%]\u001b[A\n",
            "Training:  41% 102/250 [00:19<00:22,  6.62it/s, loss=1.1966, acc=33.79%]\u001b[A\n",
            "Training:  41% 102/250 [00:20<00:22,  6.62it/s, loss=1.0439, acc=34.04%]\u001b[A\n",
            "Training:  41% 102/250 [00:20<00:22,  6.62it/s, loss=1.2351, acc=34.22%]\u001b[A\n",
            "Training:  42% 104/250 [00:20<00:18,  7.82it/s, loss=1.2351, acc=34.22%]\u001b[A\n",
            "Training:  42% 104/250 [00:20<00:18,  7.82it/s, loss=1.2674, acc=34.40%]\u001b[A\n",
            "Training:  42% 104/250 [00:20<00:18,  7.82it/s, loss=1.3793, acc=34.55%]\u001b[A\n",
            "Training:  42% 106/250 [00:20<00:21,  6.69it/s, loss=1.3793, acc=34.55%]\u001b[A\n",
            "Training:  42% 106/250 [00:20<00:21,  6.69it/s, loss=1.3546, acc=34.70%]\u001b[A\n",
            "Training:  43% 107/250 [00:20<00:20,  7.15it/s, loss=1.3546, acc=34.70%]\u001b[A\n",
            "Training:  43% 107/250 [00:20<00:20,  7.15it/s, loss=1.2857, acc=34.92%]\u001b[A\n",
            "Training:  43% 108/250 [00:20<00:18,  7.62it/s, loss=1.2857, acc=34.92%]\u001b[A\n",
            "Training:  43% 108/250 [00:20<00:18,  7.62it/s, loss=1.2006, acc=35.12%]\u001b[A\n",
            "Training:  44% 109/250 [00:20<00:17,  7.99it/s, loss=1.2006, acc=35.12%]\u001b[A\n",
            "Training:  44% 109/250 [00:21<00:17,  7.99it/s, loss=1.0438, acc=35.43%]\u001b[A\n",
            "Training:  44% 110/250 [00:21<00:21,  6.54it/s, loss=1.0438, acc=35.43%]\u001b[A\n",
            "Training:  44% 110/250 [00:21<00:21,  6.54it/s, loss=1.5714, acc=35.44%]\u001b[A\n",
            "Training:  44% 110/250 [00:21<00:21,  6.54it/s, loss=1.4304, acc=35.60%]\u001b[A\n",
            "Training:  45% 112/250 [00:21<00:17,  7.68it/s, loss=1.4304, acc=35.60%]\u001b[A\n",
            "Training:  45% 112/250 [00:21<00:17,  7.68it/s, loss=1.2430, acc=35.70%]\u001b[A\n",
            "Training:  45% 113/250 [00:21<00:17,  8.05it/s, loss=1.2430, acc=35.70%]\u001b[A\n",
            "Training:  45% 113/250 [00:21<00:17,  8.05it/s, loss=1.2974, acc=35.80%]\u001b[A\n",
            "Training:  46% 114/250 [00:21<00:18,  7.50it/s, loss=1.2974, acc=35.80%]\u001b[A\n",
            "Training:  46% 114/250 [00:21<00:18,  7.50it/s, loss=1.1499, acc=35.95%]\u001b[A\n",
            "Training:  46% 115/250 [00:21<00:17,  7.94it/s, loss=1.1499, acc=35.95%]\u001b[A\n",
            "Training:  46% 115/250 [00:21<00:17,  7.94it/s, loss=1.4438, acc=35.99%]\u001b[A\n",
            "Training:  46% 116/250 [00:21<00:16,  8.27it/s, loss=1.4438, acc=35.99%]\u001b[A\n",
            "Training:  46% 116/250 [00:21<00:16,  8.27it/s, loss=1.2532, acc=36.14%]\u001b[A\n",
            "Training:  46% 116/250 [00:21<00:16,  8.27it/s, loss=1.2313, acc=36.26%]\u001b[A\n",
            "Training:  47% 118/250 [00:21<00:16,  7.78it/s, loss=1.2313, acc=36.26%]\u001b[A\n",
            "Training:  47% 118/250 [00:22<00:16,  7.78it/s, loss=1.3155, acc=36.40%]\u001b[A\n",
            "Training:  47% 118/250 [00:22<00:16,  7.78it/s, loss=1.5179, acc=36.46%]\u001b[A\n",
            "Training:  48% 120/250 [00:22<00:15,  8.56it/s, loss=1.5179, acc=36.46%]\u001b[A\n",
            "Training:  48% 120/250 [00:22<00:15,  8.56it/s, loss=1.1641, acc=36.57%]\u001b[A\n",
            "Training:  48% 120/250 [00:22<00:15,  8.56it/s, loss=1.1300, acc=36.89%]\u001b[A\n",
            "Training:  49% 122/250 [00:22<00:17,  7.34it/s, loss=1.1300, acc=36.89%]\u001b[A\n",
            "Training:  49% 122/250 [00:22<00:17,  7.34it/s, loss=1.1700, acc=37.04%]\u001b[A\n",
            "Training:  49% 122/250 [00:22<00:17,  7.34it/s, loss=1.2418, acc=37.17%]\u001b[A\n",
            "Training:  50% 124/250 [00:22<00:15,  8.04it/s, loss=1.2418, acc=37.17%]\u001b[A\n",
            "Training:  50% 124/250 [00:22<00:15,  8.04it/s, loss=1.1670, acc=37.38%]\u001b[A\n",
            "Training:  50% 125/250 [00:22<00:15,  8.32it/s, loss=1.1670, acc=37.38%]\u001b[A\n",
            "Training:  50% 125/250 [00:23<00:15,  8.32it/s, loss=1.0844, acc=37.57%]\u001b[A\n",
            "Training:  50% 126/250 [00:23<00:19,  6.29it/s, loss=1.0844, acc=37.57%]\u001b[A\n",
            "Training:  50% 126/250 [00:23<00:19,  6.29it/s, loss=1.1183, acc=37.77%]\u001b[A\n",
            "Training:  50% 126/250 [00:23<00:19,  6.29it/s, loss=1.0208, acc=37.94%]\u001b[A\n",
            "Training:  51% 128/250 [00:23<00:16,  7.38it/s, loss=1.0208, acc=37.94%]\u001b[A\n",
            "Training:  51% 128/250 [00:23<00:16,  7.38it/s, loss=1.1011, acc=38.08%]\u001b[A\n",
            "Training:  51% 128/250 [00:23<00:16,  7.38it/s, loss=0.9641, acc=38.27%]\u001b[A\n",
            "Training:  52% 130/250 [00:23<00:16,  7.40it/s, loss=0.9641, acc=38.27%]\u001b[A\n",
            "Training:  52% 130/250 [00:23<00:16,  7.40it/s, loss=1.2751, acc=38.38%]\u001b[A\n",
            "Training:  52% 131/250 [00:23<00:15,  7.77it/s, loss=1.2751, acc=38.38%]\u001b[A\n",
            "Training:  52% 131/250 [00:23<00:15,  7.77it/s, loss=0.9319, acc=38.64%]\u001b[A\n",
            "Training:  52% 131/250 [00:23<00:15,  7.77it/s, loss=1.1207, acc=38.77%]\u001b[A\n",
            "Training:  53% 133/250 [00:23<00:13,  8.48it/s, loss=1.1207, acc=38.77%]\u001b[A\n",
            "Training:  53% 133/250 [00:24<00:13,  8.48it/s, loss=1.3725, acc=38.88%]\u001b[A\n",
            "Training:  54% 134/250 [00:24<00:15,  7.56it/s, loss=1.3725, acc=38.88%]\u001b[A\n",
            "Training:  54% 134/250 [00:24<00:15,  7.56it/s, loss=1.0969, acc=39.07%]\u001b[A\n",
            "Training:  54% 135/250 [00:24<00:14,  7.89it/s, loss=1.0969, acc=39.07%]\u001b[A\n",
            "Training:  54% 135/250 [00:24<00:14,  7.89it/s, loss=1.0293, acc=39.32%]\u001b[A\n",
            "Training:  54% 136/250 [00:24<00:13,  8.27it/s, loss=1.0293, acc=39.32%]\u001b[A\n",
            "Training:  54% 136/250 [00:24<00:13,  8.27it/s, loss=1.1515, acc=39.39%]\u001b[A\n",
            "Training:  55% 137/250 [00:24<00:13,  8.50it/s, loss=1.1515, acc=39.39%]\u001b[A\n",
            "Training:  55% 137/250 [00:24<00:13,  8.50it/s, loss=0.8753, acc=39.56%]\u001b[A\n",
            "Training:  55% 138/250 [00:24<00:18,  6.13it/s, loss=0.8753, acc=39.56%]\u001b[A\n",
            "Training:  55% 138/250 [00:24<00:18,  6.13it/s, loss=1.0180, acc=39.68%]\u001b[A\n",
            "Training:  56% 139/250 [00:24<00:16,  6.81it/s, loss=1.0180, acc=39.68%]\u001b[A\n",
            "Training:  56% 139/250 [00:24<00:16,  6.81it/s, loss=0.8508, acc=39.89%]\u001b[A\n",
            "Training:  56% 140/250 [00:24<00:14,  7.40it/s, loss=0.8508, acc=39.89%]\u001b[A\n",
            "Training:  56% 140/250 [00:24<00:14,  7.40it/s, loss=1.1765, acc=40.07%]\u001b[A\n",
            "Training:  56% 140/250 [00:25<00:14,  7.40it/s, loss=1.2055, acc=40.21%]\u001b[A\n",
            "Training:  57% 142/250 [00:25<00:17,  6.11it/s, loss=1.2055, acc=40.21%]\u001b[A\n",
            "Training:  57% 142/250 [00:25<00:17,  6.11it/s, loss=1.1259, acc=40.38%]\u001b[A\n",
            "Training:  57% 142/250 [00:25<00:17,  6.11it/s, loss=1.5486, acc=40.32%]\u001b[A\n",
            "Training:  58% 144/250 [00:25<00:14,  7.34it/s, loss=1.5486, acc=40.32%]\u001b[A\n",
            "Training:  58% 144/250 [00:25<00:14,  7.34it/s, loss=1.2456, acc=40.43%]\u001b[A\n",
            "Training:  58% 144/250 [00:25<00:14,  7.34it/s, loss=1.2489, acc=40.50%]\u001b[A\n",
            "Training:  58% 146/250 [00:25<00:18,  5.61it/s, loss=1.2489, acc=40.50%]\u001b[A\n",
            "Training:  58% 146/250 [00:26<00:18,  5.61it/s, loss=0.9809, acc=40.62%]\u001b[A\n",
            "Training:  59% 147/250 [00:26<00:17,  5.95it/s, loss=0.9809, acc=40.62%]\u001b[A\n",
            "Training:  59% 147/250 [00:26<00:17,  5.95it/s, loss=1.2162, acc=40.73%]\u001b[A\n",
            "Training:  59% 148/250 [00:26<00:16,  6.35it/s, loss=1.2162, acc=40.73%]\u001b[A\n",
            "Training:  59% 148/250 [00:26<00:16,  6.35it/s, loss=1.1053, acc=40.90%]\u001b[A\n",
            "Training:  60% 149/250 [00:26<00:15,  6.69it/s, loss=1.1053, acc=40.90%]\u001b[A\n",
            "Training:  60% 149/250 [00:26<00:15,  6.69it/s, loss=1.1466, acc=40.94%]\u001b[A\n",
            "Training:  60% 150/250 [00:26<00:23,  4.34it/s, loss=1.1466, acc=40.94%]\u001b[A\n",
            "Training:  60% 150/250 [00:26<00:23,  4.34it/s, loss=1.1167, acc=41.02%]\u001b[A\n",
            "Training:  60% 151/250 [00:26<00:20,  4.95it/s, loss=1.1167, acc=41.02%]\u001b[A\n",
            "Training:  60% 151/250 [00:27<00:20,  4.95it/s, loss=1.0791, acc=41.16%]\u001b[A\n",
            "Training:  61% 152/250 [00:27<00:17,  5.51it/s, loss=1.0791, acc=41.16%]\u001b[A\n",
            "Training:  61% 152/250 [00:27<00:17,  5.51it/s, loss=0.9698, acc=41.30%]\u001b[A\n",
            "Training:  61% 153/250 [00:27<00:15,  6.09it/s, loss=0.9698, acc=41.30%]\u001b[A\n",
            "Training:  61% 153/250 [00:27<00:15,  6.09it/s, loss=0.9483, acc=41.44%]\u001b[A\n",
            "Training:  62% 154/250 [00:27<00:23,  4.13it/s, loss=0.9483, acc=41.44%]\u001b[A\n",
            "Training:  62% 154/250 [00:27<00:23,  4.13it/s, loss=1.2978, acc=41.55%]\u001b[A\n",
            "Training:  62% 155/250 [00:27<00:19,  4.81it/s, loss=1.2978, acc=41.55%]\u001b[A\n",
            "Training:  62% 155/250 [00:27<00:19,  4.81it/s, loss=1.0250, acc=41.65%]\u001b[A\n",
            "Training:  62% 156/250 [00:27<00:16,  5.54it/s, loss=1.0250, acc=41.65%]\u001b[A\n",
            "Training:  62% 156/250 [00:27<00:16,  5.54it/s, loss=0.9789, acc=41.72%]\u001b[A\n",
            "Training:  63% 157/250 [00:27<00:14,  6.21it/s, loss=0.9789, acc=41.72%]\u001b[A\n",
            "Training:  63% 157/250 [00:28<00:14,  6.21it/s, loss=1.2382, acc=41.79%]\u001b[A\n",
            "Training:  63% 158/250 [00:28<00:24,  3.82it/s, loss=1.2382, acc=41.79%]\u001b[A\n",
            "Training:  63% 158/250 [00:28<00:24,  3.82it/s, loss=1.0988, acc=41.82%]\u001b[A\n",
            "Training:  64% 159/250 [00:28<00:20,  4.51it/s, loss=1.0988, acc=41.82%]\u001b[A\n",
            "Training:  64% 159/250 [00:28<00:20,  4.51it/s, loss=1.3479, acc=41.82%]\u001b[A\n",
            "Training:  64% 160/250 [00:28<00:18,  4.99it/s, loss=1.3479, acc=41.82%]\u001b[A\n",
            "Training:  64% 160/250 [00:28<00:18,  4.99it/s, loss=1.1302, acc=41.94%]\u001b[A\n",
            "Training:  64% 161/250 [00:28<00:15,  5.60it/s, loss=1.1302, acc=41.94%]\u001b[A\n",
            "Training:  64% 161/250 [00:29<00:15,  5.60it/s, loss=1.3768, acc=41.96%]\u001b[A\n",
            "Training:  65% 162/250 [00:29<00:22,  3.88it/s, loss=1.3768, acc=41.96%]\u001b[A\n",
            "Training:  65% 162/250 [00:29<00:22,  3.88it/s, loss=1.0237, acc=42.01%]\u001b[A\n",
            "Training:  65% 163/250 [00:29<00:18,  4.68it/s, loss=1.0237, acc=42.01%]\u001b[A\n",
            "Training:  65% 163/250 [00:29<00:18,  4.68it/s, loss=0.9670, acc=42.13%]\u001b[A\n",
            "Training:  66% 164/250 [00:29<00:16,  5.35it/s, loss=0.9670, acc=42.13%]\u001b[A\n",
            "Training:  66% 164/250 [00:29<00:16,  5.35it/s, loss=0.7766, acc=42.27%]\u001b[A\n",
            "Training:  66% 165/250 [00:29<00:14,  5.80it/s, loss=0.7766, acc=42.27%]\u001b[A\n",
            "Training:  66% 165/250 [00:30<00:14,  5.80it/s, loss=0.9622, acc=42.34%]\u001b[A\n",
            "Training:  66% 166/250 [00:30<00:26,  3.22it/s, loss=0.9622, acc=42.34%]\u001b[A\n",
            "Training:  66% 166/250 [00:30<00:26,  3.22it/s, loss=1.2969, acc=42.35%]\u001b[A\n",
            "Training:  67% 167/250 [00:30<00:21,  3.89it/s, loss=1.2969, acc=42.35%]\u001b[A\n",
            "Training:  67% 167/250 [00:30<00:21,  3.89it/s, loss=1.1710, acc=42.43%]\u001b[A\n",
            "Training:  67% 168/250 [00:30<00:17,  4.71it/s, loss=1.1710, acc=42.43%]\u001b[A\n",
            "Training:  67% 168/250 [00:30<00:17,  4.71it/s, loss=0.9963, acc=42.51%]\u001b[A\n",
            "Training:  68% 169/250 [00:30<00:15,  5.36it/s, loss=0.9963, acc=42.51%]\u001b[A\n",
            "Training:  68% 169/250 [00:31<00:15,  5.36it/s, loss=0.8577, acc=42.65%]\u001b[A\n",
            "Training:  68% 170/250 [00:31<00:21,  3.70it/s, loss=0.8577, acc=42.65%]\u001b[A\n",
            "Training:  68% 170/250 [00:31<00:21,  3.70it/s, loss=0.8922, acc=42.78%]\u001b[A\n",
            "Training:  68% 170/250 [00:31<00:21,  3.70it/s, loss=0.9004, acc=42.90%]\u001b[A\n",
            "Training:  69% 172/250 [00:31<00:14,  5.24it/s, loss=0.9004, acc=42.90%]\u001b[A\n",
            "Training:  69% 172/250 [00:31<00:14,  5.24it/s, loss=0.7944, acc=42.99%]\u001b[A\n",
            "Training:  69% 173/250 [00:31<00:12,  5.93it/s, loss=0.7944, acc=42.99%]\u001b[A\n",
            "Training:  69% 173/250 [00:31<00:12,  5.93it/s, loss=0.9817, acc=43.09%]\u001b[A\n",
            "Training:  70% 174/250 [00:31<00:14,  5.33it/s, loss=0.9817, acc=43.09%]\u001b[A\n",
            "Training:  70% 174/250 [00:31<00:14,  5.33it/s, loss=1.0996, acc=43.18%]\u001b[A\n",
            "Training:  70% 175/250 [00:31<00:12,  6.00it/s, loss=1.0996, acc=43.18%]\u001b[A\n",
            "Training:  70% 175/250 [00:31<00:12,  6.00it/s, loss=1.1250, acc=43.24%]\u001b[A\n",
            "Training:  70% 175/250 [00:32<00:12,  6.00it/s, loss=0.9278, acc=43.34%]\u001b[A\n",
            "Training:  71% 177/250 [00:32<00:09,  7.46it/s, loss=0.9278, acc=43.34%]\u001b[A\n",
            "Training:  71% 177/250 [00:32<00:09,  7.46it/s, loss=0.7556, acc=43.52%]\u001b[A\n",
            "Training:  71% 178/250 [00:32<00:09,  7.80it/s, loss=0.7556, acc=43.52%]\u001b[A\n",
            "Training:  71% 178/250 [00:32<00:09,  7.80it/s, loss=0.7149, acc=43.63%]\u001b[A\n",
            "Training:  72% 179/250 [00:32<00:08,  8.22it/s, loss=0.7149, acc=43.63%]\u001b[A\n",
            "Training:  72% 179/250 [00:32<00:08,  8.22it/s, loss=0.7941, acc=43.78%]\u001b[A\n",
            "Training:  72% 179/250 [00:32<00:08,  8.22it/s, loss=1.3867, acc=43.77%]\u001b[A\n",
            "Training:  72% 181/250 [00:32<00:07,  8.81it/s, loss=1.3867, acc=43.77%]\u001b[A\n",
            "Training:  72% 181/250 [00:32<00:07,  8.81it/s, loss=1.1213, acc=43.82%]\u001b[A\n",
            "Training:  73% 182/250 [00:32<00:12,  5.54it/s, loss=1.1213, acc=43.82%]\u001b[A\n",
            "Training:  73% 182/250 [00:32<00:12,  5.54it/s, loss=0.7450, acc=43.99%]\u001b[A\n",
            "Training:  73% 182/250 [00:33<00:12,  5.54it/s, loss=0.9915, acc=44.02%]\u001b[A\n",
            "Training:  74% 184/250 [00:33<00:09,  6.84it/s, loss=0.9915, acc=44.02%]\u001b[A\n",
            "Training:  74% 184/250 [00:33<00:09,  6.84it/s, loss=0.7826, acc=44.14%]\u001b[A\n",
            "Training:  74% 185/250 [00:33<00:08,  7.33it/s, loss=0.7826, acc=44.14%]\u001b[A\n",
            "Training:  74% 185/250 [00:33<00:08,  7.33it/s, loss=1.1062, acc=44.24%]\u001b[A\n",
            "Training:  74% 186/250 [00:33<00:10,  5.90it/s, loss=1.1062, acc=44.24%]\u001b[A\n",
            "Training:  74% 186/250 [00:33<00:10,  5.90it/s, loss=0.9357, acc=44.35%]\u001b[A\n",
            "Training:  75% 187/250 [00:33<00:09,  6.51it/s, loss=0.9357, acc=44.35%]\u001b[A\n",
            "Training:  75% 187/250 [00:33<00:09,  6.51it/s, loss=0.8644, acc=44.48%]\u001b[A\n",
            "Training:  75% 188/250 [00:33<00:08,  7.16it/s, loss=0.8644, acc=44.48%]\u001b[A\n",
            "Training:  75% 188/250 [00:33<00:08,  7.16it/s, loss=0.9745, acc=44.61%]\u001b[A\n",
            "Training:  76% 189/250 [00:33<00:07,  7.66it/s, loss=0.9745, acc=44.61%]\u001b[A\n",
            "Training:  76% 189/250 [00:33<00:07,  7.66it/s, loss=0.7072, acc=44.77%]\u001b[A\n",
            "Training:  76% 190/250 [00:33<00:10,  6.00it/s, loss=0.7072, acc=44.77%]\u001b[A\n",
            "Training:  76% 190/250 [00:34<00:10,  6.00it/s, loss=0.9637, acc=44.85%]\u001b[A\n",
            "Training:  76% 190/250 [00:34<00:10,  6.00it/s, loss=0.9515, acc=44.95%]\u001b[A\n",
            "Training:  77% 192/250 [00:34<00:07,  7.25it/s, loss=0.9515, acc=44.95%]\u001b[A\n",
            "Training:  77% 192/250 [00:34<00:07,  7.25it/s, loss=1.1628, acc=44.98%]\u001b[A\n",
            "Training:  77% 193/250 [00:34<00:07,  7.59it/s, loss=1.1628, acc=44.98%]\u001b[A\n",
            "Training:  77% 193/250 [00:34<00:07,  7.59it/s, loss=0.7751, acc=45.15%]\u001b[A\n",
            "Training:  78% 194/250 [00:34<00:09,  6.10it/s, loss=0.7751, acc=45.15%]\u001b[A\n",
            "Training:  78% 194/250 [00:34<00:09,  6.10it/s, loss=0.7284, acc=45.34%]\u001b[A\n",
            "Training:  78% 194/250 [00:34<00:09,  6.10it/s, loss=0.7753, acc=45.44%]\u001b[A\n",
            "Training:  78% 196/250 [00:34<00:07,  7.19it/s, loss=0.7753, acc=45.44%]\u001b[A\n",
            "Training:  78% 196/250 [00:34<00:07,  7.19it/s, loss=1.1545, acc=45.48%]\u001b[A\n",
            "Training:  79% 197/250 [00:34<00:07,  7.49it/s, loss=1.1545, acc=45.48%]\u001b[A\n",
            "Training:  79% 197/250 [00:35<00:07,  7.49it/s, loss=0.9491, acc=45.55%]\u001b[A\n",
            "Training:  79% 198/250 [00:35<00:07,  7.26it/s, loss=0.9491, acc=45.55%]\u001b[A\n",
            "Training:  79% 198/250 [00:35<00:07,  7.26it/s, loss=1.1651, acc=45.62%]\u001b[A\n",
            "Training:  79% 198/250 [00:35<00:07,  7.26it/s, loss=0.9804, acc=45.70%]\u001b[A\n",
            "Training:  80% 200/250 [00:35<00:06,  8.14it/s, loss=0.9804, acc=45.70%]\u001b[A\n",
            "Training:  80% 200/250 [00:35<00:06,  8.14it/s, loss=1.1845, acc=45.77%]\u001b[A\n",
            "Training:  80% 201/250 [00:35<00:05,  8.37it/s, loss=1.1845, acc=45.77%]\u001b[A\n",
            "Training:  80% 201/250 [00:35<00:05,  8.37it/s, loss=1.1708, acc=45.81%]\u001b[A\n",
            "Training:  81% 202/250 [00:35<00:05,  8.55it/s, loss=1.1708, acc=45.81%]\u001b[A\n",
            "Training:  81% 202/250 [00:35<00:05,  8.55it/s, loss=0.6823, acc=45.92%]\u001b[A\n",
            "Training:  81% 202/250 [00:35<00:05,  8.55it/s, loss=1.0002, acc=45.99%]\u001b[A\n",
            "Training:  82% 204/250 [00:35<00:05,  9.07it/s, loss=1.0002, acc=45.99%]\u001b[A\n",
            "Training:  82% 204/250 [00:35<00:05,  9.07it/s, loss=1.0888, acc=46.02%]\u001b[A\n",
            "Training:  82% 205/250 [00:35<00:05,  8.59it/s, loss=1.0888, acc=46.02%]\u001b[A\n",
            "Training:  82% 205/250 [00:36<00:05,  8.59it/s, loss=1.0480, acc=46.10%]\u001b[A\n",
            "Training:  82% 206/250 [00:36<00:07,  5.57it/s, loss=1.0480, acc=46.10%]\u001b[A\n",
            "Training:  82% 206/250 [00:36<00:07,  5.57it/s, loss=1.2452, acc=46.14%]\u001b[A\n",
            "Training:  83% 207/250 [00:36<00:06,  6.28it/s, loss=1.2452, acc=46.14%]\u001b[A\n",
            "Training:  83% 207/250 [00:36<00:06,  6.28it/s, loss=0.8267, acc=46.24%]\u001b[A\n",
            "Training:  83% 208/250 [00:36<00:06,  6.94it/s, loss=0.8267, acc=46.24%]\u001b[A\n",
            "Training:  83% 208/250 [00:36<00:06,  6.94it/s, loss=1.1005, acc=46.28%]\u001b[A\n",
            "Training:  84% 209/250 [00:36<00:05,  7.34it/s, loss=1.1005, acc=46.28%]\u001b[A\n",
            "Training:  84% 209/250 [00:36<00:05,  7.34it/s, loss=0.7607, acc=46.37%]\u001b[A\n",
            "Training:  84% 210/250 [00:36<00:06,  6.47it/s, loss=0.7607, acc=46.37%]\u001b[A\n",
            "Training:  84% 210/250 [00:36<00:06,  6.47it/s, loss=1.0645, acc=46.37%]\u001b[A\n",
            "Training:  84% 211/250 [00:36<00:05,  7.09it/s, loss=1.0645, acc=46.37%]\u001b[A\n",
            "Training:  84% 211/250 [00:36<00:05,  7.09it/s, loss=0.9852, acc=46.45%]\u001b[A\n",
            "Training:  84% 211/250 [00:36<00:05,  7.09it/s, loss=0.8772, acc=46.54%]\u001b[A\n",
            "Training:  85% 213/250 [00:36<00:04,  8.31it/s, loss=0.8772, acc=46.54%]\u001b[A\n",
            "Training:  85% 213/250 [00:37<00:04,  8.31it/s, loss=0.9544, acc=46.64%]\u001b[A\n",
            "Training:  86% 214/250 [00:37<00:05,  6.74it/s, loss=0.9544, acc=46.64%]\u001b[A\n",
            "Training:  86% 214/250 [00:37<00:05,  6.74it/s, loss=0.8320, acc=46.74%]\u001b[A\n",
            "Training:  86% 215/250 [00:37<00:04,  7.31it/s, loss=0.8320, acc=46.74%]\u001b[A\n",
            "Training:  86% 215/250 [00:37<00:04,  7.31it/s, loss=1.0463, acc=46.79%]\u001b[A\n",
            "Training:  86% 216/250 [00:37<00:04,  7.75it/s, loss=1.0463, acc=46.79%]\u001b[A\n",
            "Training:  86% 216/250 [00:37<00:04,  7.75it/s, loss=1.0124, acc=46.90%]\u001b[A\n",
            "Training:  87% 217/250 [00:37<00:04,  8.06it/s, loss=1.0124, acc=46.90%]\u001b[A\n",
            "Training:  87% 217/250 [00:37<00:04,  8.06it/s, loss=1.1909, acc=46.89%]\u001b[A\n",
            "Training:  87% 218/250 [00:37<00:04,  7.37it/s, loss=1.1909, acc=46.89%]\u001b[A\n",
            "Training:  87% 218/250 [00:37<00:04,  7.37it/s, loss=0.9376, acc=46.96%]\u001b[A\n",
            "Training:  88% 219/250 [00:37<00:03,  7.85it/s, loss=0.9376, acc=46.96%]\u001b[A\n",
            "Training:  88% 219/250 [00:37<00:03,  7.85it/s, loss=1.0047, acc=47.02%]\u001b[A\n",
            "Training:  88% 219/250 [00:37<00:03,  7.85it/s, loss=1.0153, acc=47.12%]\u001b[A\n",
            "Training:  88% 221/250 [00:37<00:03,  8.73it/s, loss=1.0153, acc=47.12%]\u001b[A\n",
            "Training:  88% 221/250 [00:38<00:03,  8.73it/s, loss=0.8045, acc=47.23%]\u001b[A\n",
            "Training:  89% 222/250 [00:38<00:04,  6.64it/s, loss=0.8045, acc=47.23%]\u001b[A\n",
            "Training:  89% 222/250 [00:38<00:04,  6.64it/s, loss=0.9288, acc=47.31%]\u001b[A\n",
            "Training:  89% 223/250 [00:38<00:03,  7.10it/s, loss=0.9288, acc=47.31%]\u001b[A\n",
            "Training:  89% 223/250 [00:38<00:03,  7.10it/s, loss=0.8974, acc=47.41%]\u001b[A\n",
            "Training:  90% 224/250 [00:38<00:03,  7.58it/s, loss=0.8974, acc=47.41%]\u001b[A\n",
            "Training:  90% 224/250 [00:38<00:03,  7.58it/s, loss=0.7172, acc=47.51%]\u001b[A\n",
            "Training:  90% 225/250 [00:38<00:03,  8.05it/s, loss=0.7172, acc=47.51%]\u001b[A\n",
            "Training:  90% 225/250 [00:38<00:03,  8.05it/s, loss=1.0509, acc=47.55%]\u001b[A\n",
            "Training:  90% 226/250 [00:38<00:03,  7.38it/s, loss=1.0509, acc=47.55%]\u001b[A\n",
            "Training:  90% 226/250 [00:38<00:03,  7.38it/s, loss=0.8235, acc=47.63%]\u001b[A\n",
            "Training:  90% 226/250 [00:38<00:03,  7.38it/s, loss=1.0521, acc=47.67%]\u001b[A\n",
            "Training:  91% 228/250 [00:38<00:02,  8.31it/s, loss=1.0521, acc=47.67%]\u001b[A\n",
            "Training:  91% 228/250 [00:39<00:02,  8.31it/s, loss=0.8772, acc=47.79%]\u001b[A\n",
            "Training:  92% 229/250 [00:39<00:02,  8.51it/s, loss=0.8772, acc=47.79%]\u001b[A\n",
            "Training:  92% 229/250 [00:39<00:02,  8.51it/s, loss=1.2592, acc=47.76%]\u001b[A\n",
            "Training:  92% 230/250 [00:39<00:02,  6.99it/s, loss=1.2592, acc=47.76%]\u001b[A\n",
            "Training:  92% 230/250 [00:39<00:02,  6.99it/s, loss=1.0406, acc=47.84%]\u001b[A\n",
            "Training:  92% 231/250 [00:39<00:02,  7.50it/s, loss=1.0406, acc=47.84%]\u001b[A\n",
            "Training:  92% 231/250 [00:39<00:02,  7.50it/s, loss=1.0340, acc=47.91%]\u001b[A\n",
            "Training:  93% 232/250 [00:39<00:02,  8.02it/s, loss=1.0340, acc=47.91%]\u001b[A\n",
            "Training:  93% 232/250 [00:39<00:02,  8.02it/s, loss=0.9115, acc=47.97%]\u001b[A\n",
            "Training:  93% 233/250 [00:39<00:02,  8.28it/s, loss=0.9115, acc=47.97%]\u001b[A\n",
            "Training:  93% 233/250 [00:39<00:02,  8.28it/s, loss=0.9839, acc=48.01%]\u001b[A\n",
            "Training:  94% 234/250 [00:39<00:01,  8.25it/s, loss=0.9839, acc=48.01%]\u001b[A\n",
            "Training:  94% 234/250 [00:39<00:01,  8.25it/s, loss=0.8317, acc=48.10%]\u001b[A\n",
            "Training:  94% 235/250 [00:39<00:01,  7.74it/s, loss=0.8317, acc=48.10%]\u001b[A\n",
            "Training:  94% 235/250 [00:39<00:01,  7.74it/s, loss=0.8086, acc=48.16%]\u001b[A\n",
            "Training:  94% 235/250 [00:40<00:01,  7.74it/s, loss=0.8748, acc=48.19%]\u001b[A\n",
            "Training:  95% 237/250 [00:40<00:01,  8.55it/s, loss=0.8748, acc=48.19%]\u001b[A\n",
            "Training:  95% 237/250 [00:40<00:01,  8.55it/s, loss=1.0312, acc=48.28%]\u001b[A\n",
            "Training:  95% 238/250 [00:40<00:01,  8.72it/s, loss=1.0312, acc=48.28%]\u001b[A\n",
            "Training:  95% 238/250 [00:40<00:01,  8.72it/s, loss=0.6832, acc=48.38%]\u001b[A\n",
            "Training:  96% 239/250 [00:40<00:01,  8.09it/s, loss=0.6832, acc=48.38%]\u001b[A\n",
            "Training:  96% 239/250 [00:40<00:01,  8.09it/s, loss=0.8814, acc=48.44%]\u001b[A\n",
            "Training:  96% 240/250 [00:40<00:01,  8.17it/s, loss=0.8814, acc=48.44%]\u001b[A\n",
            "Training:  96% 240/250 [00:40<00:01,  8.17it/s, loss=1.1185, acc=48.46%]\u001b[A\n",
            "Training:  96% 241/250 [00:40<00:01,  5.81it/s, loss=1.1185, acc=48.46%]\u001b[A\n",
            "Training:  96% 241/250 [00:40<00:01,  5.81it/s, loss=0.7248, acc=48.59%]\u001b[A\n",
            "Training:  97% 242/250 [00:40<00:01,  5.99it/s, loss=0.7248, acc=48.59%]\u001b[A\n",
            "Training:  97% 242/250 [00:41<00:01,  5.99it/s, loss=0.9159, acc=48.64%]\u001b[A\n",
            "Training:  97% 243/250 [00:41<00:01,  6.52it/s, loss=0.9159, acc=48.64%]\u001b[A\n",
            "Training:  97% 243/250 [00:41<00:01,  6.52it/s, loss=0.6565, acc=48.76%]\u001b[A\n",
            "Training:  98% 244/250 [00:41<00:00,  6.74it/s, loss=0.6565, acc=48.76%]\u001b[A\n",
            "Training:  98% 244/250 [00:41<00:00,  6.74it/s, loss=0.7808, acc=48.84%]\u001b[A\n",
            "Training:  98% 245/250 [00:41<00:01,  4.18it/s, loss=0.7808, acc=48.84%]\u001b[A\n",
            "Training:  98% 245/250 [00:41<00:01,  4.18it/s, loss=0.6810, acc=48.95%]\u001b[A\n",
            "Training:  98% 246/250 [00:41<00:00,  5.01it/s, loss=0.6810, acc=48.95%]\u001b[A\n",
            "Training:  98% 246/250 [00:41<00:00,  5.01it/s, loss=0.9798, acc=49.01%]\u001b[A\n",
            "Training:  99% 247/250 [00:41<00:00,  5.86it/s, loss=0.9798, acc=49.01%]\u001b[A\n",
            "Training:  99% 247/250 [00:41<00:00,  5.86it/s, loss=0.9973, acc=49.03%]\u001b[A\n",
            "Training:  99% 247/250 [00:42<00:00,  5.86it/s, loss=0.6550, acc=49.12%]\u001b[A\n",
            "Training: 100% 249/250 [00:42<00:00,  6.81it/s, loss=0.6550, acc=49.12%]\u001b[A\n",
            "Training: 100% 250/250 [00:42<00:00,  5.92it/s, loss=1.0183, acc=49.17%]\n",
            "Validating: 100% 32/32 [00:05<00:00,  5.70it/s]\n",
            "Epoch 1: Train Loss=1.3696, Acc=49.17% | Val Loss=0.7977, Acc=67.80%\n",
            "--> New best model saved with Val Acc: 67.80%\n",
            "\n",
            "Epoch 2/20\n",
            "Training: 100% 250/250 [00:38<00:00,  6.48it/s, loss=0.9259, acc=68.17%]\n",
            "Validating: 100% 32/32 [00:04<00:00,  6.53it/s]\n",
            "Epoch 2: Train Loss=0.7556, Acc=68.17% | Val Loss=0.7080, Acc=69.80%\n",
            "--> New best model saved with Val Acc: 69.80%\n",
            "\n",
            "Epoch 3/20\n",
            "Training: 100% 250/250 [00:38<00:00,  6.51it/s, loss=0.5838, acc=73.92%]\n",
            "Validating: 100% 32/32 [00:04<00:00,  6.98it/s]\n",
            "Epoch 3: Train Loss=0.6211, Acc=73.92% | Val Loss=0.6027, Acc=73.90%\n",
            "--> New best model saved with Val Acc: 73.90%\n",
            "\n",
            "Epoch 4/20\n",
            "Training: 100% 250/250 [00:38<00:00,  6.52it/s, loss=0.5624, acc=76.71%]\n",
            "Validating: 100% 32/32 [00:04<00:00,  6.93it/s]\n",
            "Epoch 4: Train Loss=0.5520, Acc=76.71% | Val Loss=0.5623, Acc=75.00%\n",
            "--> New best model saved with Val Acc: 75.00%\n",
            "\n",
            "Epoch 5/20\n",
            "Training: 100% 250/250 [00:38<00:00,  6.54it/s, loss=0.5362, acc=78.27%]\n",
            "Validating: 100% 32/32 [00:04<00:00,  7.07it/s]\n",
            "Epoch 5: Train Loss=0.5054, Acc=78.27% | Val Loss=0.5842, Acc=74.60%\n",
            "\n",
            "Epoch 6/20\n",
            "Training: 100% 250/250 [00:38<00:00,  6.43it/s, loss=0.3503, acc=80.75%]\n",
            "Validating: 100% 32/32 [00:04<00:00,  6.99it/s]\n",
            "Epoch 6: Train Loss=0.4668, Acc=80.75% | Val Loss=0.4891, Acc=80.00%\n",
            "--> New best model saved with Val Acc: 80.00%\n",
            "\n",
            "Epoch 7/20\n",
            "Training: 100% 250/250 [00:38<00:00,  6.53it/s, loss=0.6384, acc=82.49%]\n",
            "Validating: 100% 32/32 [00:04<00:00,  6.95it/s]\n",
            "Epoch 7: Train Loss=0.4212, Acc=82.49% | Val Loss=0.5277, Acc=79.70%\n",
            "\n",
            "Epoch 8/20\n",
            "Training: 100% 250/250 [00:38<00:00,  6.52it/s, loss=0.4410, acc=84.02%]\n",
            "Validating: 100% 32/32 [00:04<00:00,  6.73it/s]\n",
            "Epoch 8: Train Loss=0.3802, Acc=84.02% | Val Loss=0.5700, Acc=76.30%\n",
            "\n",
            "Epoch 9/20\n",
            "Training: 100% 250/250 [00:38<00:00,  6.52it/s, loss=0.3441, acc=84.44%]\n",
            "Validating: 100% 32/32 [00:04<00:00,  6.93it/s]\n",
            "Epoch 9: Train Loss=0.3675, Acc=84.44% | Val Loss=0.4824, Acc=80.80%\n",
            "--> New best model saved with Val Acc: 80.80%\n",
            "\n",
            "Epoch 10/20\n",
            "Training: 100% 250/250 [00:38<00:00,  6.51it/s, loss=0.4184, acc=85.12%]\n",
            "Validating: 100% 32/32 [00:04<00:00,  7.01it/s]\n",
            "Epoch 10: Train Loss=0.3467, Acc=85.12% | Val Loss=0.4953, Acc=80.50%\n",
            "\n",
            "Epoch 11/20\n",
            "Training: 100% 250/250 [00:38<00:00,  6.48it/s, loss=0.2669, acc=87.27%]\n",
            "Validating: 100% 32/32 [00:04<00:00,  6.96it/s]\n",
            "Epoch 11: Train Loss=0.3097, Acc=87.27% | Val Loss=0.6031, Acc=77.90%\n",
            "\n",
            "Epoch 12/20\n",
            "Training: 100% 250/250 [00:38<00:00,  6.44it/s, loss=0.2174, acc=87.11%]\n",
            "Validating:  22% 7/32 [00:01<00:03,  6.61it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --config configs/dino.json"
      ],
      "metadata": {
        "id": "z5MXZ9D6J-hW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --config configs/mfm_clip.json"
      ],
      "metadata": {
        "id": "IWI1v_VmM5MT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python clip_prompt.py --config configs/clip_prompt.json"
      ],
      "metadata": {
        "id": "TOFPc-glM7E8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python mfm_clip_prompt.py --config configs/mfm_clip_prompt.json"
      ],
      "metadata": {
        "id": "eANUzqC-NhMs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}